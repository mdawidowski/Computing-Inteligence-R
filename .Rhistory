# neuralnet
iris.nn <- neuralnet(setosa + versicolor + virginica ~
Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data=iris.training, hidden=8)
plot(iris.nn)
#ewaluacja compute
iris.predict <- compute(iris.nn, iris.test[,1:4])$net.result
idx <- apply(iris.predict, c(1), maxidx)
iris.predict <- c('setosa', 'versicolor', 'virginica')[idx]
iris.cm <- confusionMatrix(iris.predict, iris.test.labels)
print(iris.cm$table)
print(iris.cm$overall['Accuracy'])
require(neuralnet)
library(caret)
# normalizacja
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
split_species <- function(iris) {
for(x in 1:nrow(iris)){
if(iris[x,5] == "setosa") iris[x,6] = 1
if(iris[x,5] == "versicolor") iris[x,7] = 1
if(iris[x,5] == "virginica") iris[x,8] = 1
}
return (iris[,-5])
}
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
# podział
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
iris.norm <- as.data.frame(lapply(iris[1:4], normalize))
iris.norm <- cbind(iris.norm, iris$Species)
species_names <- c("setosa", "versicolor", "virginica")
species <- matrix(0, nrow = 150, ncol = 3)
colnames(species) <- species_names
iris.norm <- cbind(iris.norm, species)
iris.norm <- split_species(iris.norm)
iris.training <- iris.norm[ind==1, 1:7]
iris.test <- iris.norm[ind==2, 1:7]
iris.training.labels <- iris[ind==1, 5]
iris.test.labels <- iris[ind==2, 5]
# neuralnet
iris.nn <- neuralnet(setosa + versicolor + virginica ~
Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data=iris.training, hidden=8)
plot(iris.nn)
#ewaluacja compute
iris.predict <- compute(iris.nn, iris.test[,1:4])$net.result
idx <- apply(iris.predict, c(1), maxidx)
iris.predict <- c('setosa', 'versicolor', 'virginica')[idx]
iris.cm <- confusionMatrix(iris.predict, iris.test.labels)
print(iris.cm$table)
print(iris.cm$overall['Accuracy'])
require(neuralnet)
library(caret)
# normalizacja
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
split_species <- function(iris) {
for(x in 1:nrow(iris)){
if(iris[x,5] == "setosa") iris[x,6] = 1
if(iris[x,5] == "versicolor") iris[x,7] = 1
if(iris[x,5] == "virginica") iris[x,8] = 1
}
return (iris[,-5])
}
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
# podział
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
iris.norm <- as.data.frame(lapply(iris[1:4], normalize))
iris.norm <- cbind(iris.norm, iris$Species)
species_names <- c("setosa", "versicolor", "virginica")
species <- matrix(0, nrow = 150, ncol = 3)
colnames(species) <- species_names
iris.norm <- cbind(iris.norm, species)
iris.norm <- split_species(iris.norm)
iris.training <- iris.norm[ind==1, 1:7]
iris.test <- iris.norm[ind==2, 1:7]
iris.training.labels <- iris[ind==1, 5]
iris.test.labels <- iris[ind==2, 5]
# neuralnet
iris.nn <- neuralnet(setosa + versicolor + virginica ~
Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data=iris.training, hidden=6)
plot(iris.nn)
#ewaluacja compute
iris.predict <- compute(iris.nn, iris.test[,1:4])$net.result
idx <- apply(iris.predict, c(1), maxidx)
iris.predict <- c('setosa', 'versicolor', 'virginica')[idx]
iris.cm <- confusionMatrix(iris.predict, iris.test.labels)
print(iris.cm$table)
print(iris.cm$overall['Accuracy'])
require(neuralnet)
library(caret)
# normalizacja
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
split_species <- function(iris) {
for(x in 1:nrow(iris)){
if(iris[x,5] == "setosa") iris[x,6] = 1
if(iris[x,5] == "versicolor") iris[x,7] = 1
if(iris[x,5] == "virginica") iris[x,8] = 1
}
return (iris[,-5])
}
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
# podział
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
iris.norm <- as.data.frame(lapply(iris[1:4], normalize))
iris.norm <- cbind(iris.norm, iris$Species)
species_names <- c("setosa", "versicolor", "virginica")
species <- matrix(0, nrow = 150, ncol = 3)
colnames(species) <- species_names
iris.norm <- cbind(iris.norm, species)
iris.norm <- split_species(iris.norm)
iris.training <- iris.norm[ind==1, 1:7]
iris.test <- iris.norm[ind==2, 1:7]
iris.training.labels <- iris[ind==1, 5]
iris.test.labels <- iris[ind==2, 5]
# neuralnet
iris.nn <- neuralnet(setosa + versicolor + virginica ~
Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data=iris.training, hidden=4)
plot(iris.nn)
#ewaluacja compute
iris.predict <- compute(iris.nn, iris.test[,1:4])$net.result
idx <- apply(iris.predict, c(1), maxidx)
iris.predict <- c('setosa', 'versicolor', 'virginica')[idx]
iris.cm <- confusionMatrix(iris.predict, iris.test.labels)
print(iris.cm$table)
print(iris.cm$overall['Accuracy'])
require(neuralnet)
library(caret)
library(deducorrect)
library(class)
library(e1071)
library(party)
#
normalize <- function(x)
{
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
# Dane
womens <- read.csv("/home/marcin/Computing-Inteligence-R/Lab6/diabetes.csv", header=TRUE, sep=",")
womens.norm <- as.data.frame(lapply(womens[1:8], normalize))
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.norm$positive <- c(womens$class == "tested_positive")
womens.norm$negative <- c(womens$class == "tested_negative")
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
womens.norm.training <- womens.norm[ind==1, 1:10]
womens.norm.test <- womens.norm[ind==2, 1:10]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
womens_pred1 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=1)
womens_pred3 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=3)
womens_pred5 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=5)
womens_pred11 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=11)
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
cm_knn3 <- confusionMatrix(womens_pred3, womens.testLabels)
cm_knn5 <- confusionMatrix(womens_pred5, womens.testLabels)
cm_knn11 <- confusionMatrix(womens_pred11, womens.testLabels)
knn1_accuracy <- cm_knn1$overall['Accuracy']
knn3_accuracy <- cm_knn3$overall['Accuracy']
knn5_accuracy <- cm_knn5$overall['Accuracy']
knn11_accuracy <- cm_knn11$overall['Accuracy']
knn1_tp <- cm_knn1$table["tested_negative","tested_negative"]
knn3_tp <- cm_knn3$table["tested_negative","tested_negative"]
knn5_tp <- cm_knn5$table["tested_negative","tested_negative"]
knn11_tp <- cm_knn11$table["tested_negative","tested_negative"]
knn1_tn <- cm_knn1$table["tested_positive","tested_positive"]
knn3_tn <- cm_knn3$table["tested_positive","tested_positive"]
knn5_tn <- cm_knn5$table["tested_positive","tested_positive"]
knn11_tn <- cm_knn11$table["tested_positive","tested_positive"]
knn1_fn <- cm_knn1$table["tested_negative","tested_positive"]
knn3_fn <- cm_knn3$table["tested_negative","tested_positive"]
knn5_fn <- cm_knn5$table["tested_negative","tested_positive"]
knn11_fn <- cm_knn11$table["tested_negative","tested_positive"]
knn1_fp <- cm_knn1$table["tested_positive","tested_negative"]
knn3_fp <- cm_knn3$table["tested_positive","tested_negative"]
knn5_fp <- cm_knn5$table["tested_positive","tested_negative"]
knn11_fp <- cm_knn11$table["tested_positive","tested_negative"]
knn1_fpr <- knn1_fp/(knn1_fp+knn1_tn)
knn3_fpr <- knn3_fp/(knn3_fp+knn3_tn)
knn5_fpr <- knn5_fp/(knn5_fp+knn5_tn)
knn11_fpr <- knn11_fp/(knn11_fp+knn11_tn)
knn1_tpr <- knn1_tp/(knn1_tp+knn1_fn)
knn3_tpr <- knn3_tp/(knn3_tp+knn3_fn)
knn5_tpr <- knn5_tp/(knn5_tp+knn5_fn)
knn11_tpr <- knn11_tp/(knn11_tp+knn11_fn)
# NaiveBayes
nb <- naiveBayes(class ~ ., data=womens)
nb_pred <- predict(nb, womens[,-9])
cm_nb <- confusionMatrix(nb_pred, womens[,9])
nb_accuracy <- cm_nb$overall['Accuracy']
nb_tp <- cm_nb$table["tested_negative","tested_negative"]
nb_tn <- cm_nb$table["tested_positive","tested_positive"]
nb_fn <- cm_nb$table["tested_negative","tested_positive"]
nb_fp <- cm_nb$table["tested_positive","tested_negative"]
nb_fpr <- nb_fp/(nb_fp+nb_tn)
nb_tpr <- nb_tp/(nb_tp+nb_fn)
# Drzewa
womens_ctree <- ctree(class ~., data=womens)
ctree_pred <- predict(womens_ctree, womens[,-9])
cm_ctree <- confusionMatrix(ctree_pred, womens[,9])
ctree_accuracy <- cm_ctree$overall['Accuracy']
ct_tp <- cm_ctree$table["tested_negative","tested_negative"]
ct_tn <- cm_ctree$table["tested_positive","tested_positive"]
ct_fn <- cm_ctree$table["tested_negative","tested_positive"]
ct_fp <- cm_ctree$table["tested_positive","tested_negative"]
ct_fpr <- ct_fp/(ct_fp+ct_tn)
ct_tpr <- ct_tp/(ct_tp+ct_fn)
# Sieci Neuronowe
womens.nn <- neuralnet(positive + negative ~
pregnant.times + glucose.concentr + blood.pressure + skin.thickness +
insulin + mass.index + pedigree.func + age, data=womens.norm.training, hidden=5)
womens.predict <- compute(womens.nn, womens.norm.test[,1:8])$net.result
idx <- apply(womens.predict, c(1), maxidx)
womens.predict <- c('tested_positive', 'tested_negative')[idx]
womens.cm <- confusionMatrix(womens.predict, womens.testLabels)
nn_tp <- womens.cm$table["tested_negative","tested_negative"]
nn_tn <- womens.cm$table["tested_positive","tested_positive"]
nn_fn <- womens.cm$table["tested_negative","tested_positive"]
nn_fp <- womens.cm$table["tested_positive","tested_negative"]
nn_fpr <- nn_fp/(nn_fp+nn_tn)
nn_tpr <- nn_tp/(nn_tp+nn_fn)
nn_accuracy <- womens.cm$overall['Accuracy']
# Wykres słupkowy
classificators <- matrix(c(knn1_accuracy, knn3_accuracy, knn5_accuracy, knn11_accuracy,
nb_accuracy, ctree_accuracy, nn_accuracy), ncol=7)
classificators.names <- matrix(c("1NN", "3NN", "5NN", "11NN", "NaiveBayes", "Trees", "NeuralNets"), ncol=7)
barplot(classificators, main="Skuteczność Klasyfikatorów", names.arg=classificators.names,
ylab="Skuteczność [%]", xlab="Klasyfikatory")
# Wykres punktowy
# FPR = FP/N = FP/(FP+TN) = 1 - SPC
# TPR = TP/P = TP/(TP+FN)
colors <- c("blue", "coral", "aquamarine", "cornflowerblue", "darkgreen", "burlywood3", "firebrick3")
fpr <- c(knn1_fpr, knn3_fpr, knn5_fpr, knn11_fpr, nb_fpr, ct_fpr, nn_fpr)
tpr <- c(knn1_tpr, knn3_tpr, knn5_tpr, knn11_fpr, nb_tpr, ct_tpr, nn_tpr)
plot(fpr, tpr, col=colors, bg=colors, pch=20, xlab="False Positive Rate", ylab="True Positive Rate",
main="False Positive and True Positive Ratings")
legend("bottomright", classificators.names, fill=colors)
plot(womens.nn)
require(neuralnet)
library(caret)
library(deducorrect)
library(class)
library(e1071)
library(party)
#
normalize <- function(x)
{
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
maxidx <- function(arr) {
return(which(arr == max(arr)))
}
# Dane
womens <- read.csv("/home/marcin/Computing-Inteligence-R/Lab6/diabetes.csv", header=TRUE, sep=",")
womens.norm <- as.data.frame(lapply(womens[1:8], normalize))
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.norm$positive <- c(womens$class == "tested_positive")
womens.norm$negative <- c(womens$class == "tested_negative")
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
womens.norm.training <- womens.norm[ind==1, 1:10]
womens.norm.test <- womens.norm[ind==2, 1:10]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
womens_pred1 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=1)
womens_pred3 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=3)
womens_pred5 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=5)
womens_pred11 <- knn(train = womens.training, test = womens.test, cl = womens.trainLabels, k=11)
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
cm_knn3 <- confusionMatrix(womens_pred3, womens.testLabels)
cm_knn5 <- confusionMatrix(womens_pred5, womens.testLabels)
cm_knn11 <- confusionMatrix(womens_pred11, womens.testLabels)
knn1_accuracy <- cm_knn1$overall['Accuracy']
knn3_accuracy <- cm_knn3$overall['Accuracy']
knn5_accuracy <- cm_knn5$overall['Accuracy']
knn11_accuracy <- cm_knn11$overall['Accuracy']
knn1_tp <- cm_knn1$table["tested_negative","tested_negative"]
knn3_tp <- cm_knn3$table["tested_negative","tested_negative"]
knn5_tp <- cm_knn5$table["tested_negative","tested_negative"]
knn11_tp <- cm_knn11$table["tested_negative","tested_negative"]
knn1_tn <- cm_knn1$table["tested_positive","tested_positive"]
knn3_tn <- cm_knn3$table["tested_positive","tested_positive"]
knn5_tn <- cm_knn5$table["tested_positive","tested_positive"]
knn11_tn <- cm_knn11$table["tested_positive","tested_positive"]
knn1_fn <- cm_knn1$table["tested_negative","tested_positive"]
knn3_fn <- cm_knn3$table["tested_negative","tested_positive"]
knn5_fn <- cm_knn5$table["tested_negative","tested_positive"]
knn11_fn <- cm_knn11$table["tested_negative","tested_positive"]
knn1_fp <- cm_knn1$table["tested_positive","tested_negative"]
knn3_fp <- cm_knn3$table["tested_positive","tested_negative"]
knn5_fp <- cm_knn5$table["tested_positive","tested_negative"]
knn11_fp <- cm_knn11$table["tested_positive","tested_negative"]
knn1_fpr <- knn1_fp/(knn1_fp+knn1_tn)
knn3_fpr <- knn3_fp/(knn3_fp+knn3_tn)
knn5_fpr <- knn5_fp/(knn5_fp+knn5_tn)
knn11_fpr <- knn11_fp/(knn11_fp+knn11_tn)
knn1_tpr <- knn1_tp/(knn1_tp+knn1_fn)
knn3_tpr <- knn3_tp/(knn3_tp+knn3_fn)
knn5_tpr <- knn5_tp/(knn5_tp+knn5_fn)
knn11_tpr <- knn11_tp/(knn11_tp+knn11_fn)
# NaiveBayes
nb <- naiveBayes(class ~ ., data=womens)
nb_pred <- predict(nb, womens[,-9])
cm_nb <- confusionMatrix(nb_pred, womens[,9])
nb_accuracy <- cm_nb$overall['Accuracy']
nb_tp <- cm_nb$table["tested_negative","tested_negative"]
nb_tn <- cm_nb$table["tested_positive","tested_positive"]
nb_fn <- cm_nb$table["tested_negative","tested_positive"]
nb_fp <- cm_nb$table["tested_positive","tested_negative"]
nb_fpr <- nb_fp/(nb_fp+nb_tn)
nb_tpr <- nb_tp/(nb_tp+nb_fn)
# Drzewa
womens_ctree <- ctree(class ~., data=womens)
ctree_pred <- predict(womens_ctree, womens[,-9])
cm_ctree <- confusionMatrix(ctree_pred, womens[,9])
ctree_accuracy <- cm_ctree$overall['Accuracy']
ct_tp <- cm_ctree$table["tested_negative","tested_negative"]
ct_tn <- cm_ctree$table["tested_positive","tested_positive"]
ct_fn <- cm_ctree$table["tested_negative","tested_positive"]
ct_fp <- cm_ctree$table["tested_positive","tested_negative"]
ct_fpr <- ct_fp/(ct_fp+ct_tn)
ct_tpr <- ct_tp/(ct_tp+ct_fn)
# Sieci Neuronowe
womens.nn <- neuralnet(positive + negative ~
pregnant.times + glucose.concentr + blood.pressure + skin.thickness +
insulin + mass.index + pedigree.func + age, data=womens.norm.training, hidden=5)
womens.predict <- compute(womens.nn, womens.norm.test[,1:8])$net.result
idx <- apply(womens.predict, c(1), maxidx)
womens.predict <- c('tested_positive', 'tested_negative')[idx]
womens.cm <- confusionMatrix(womens.predict, womens.testLabels)
nn_tp <- womens.cm$table["tested_negative","tested_negative"]
nn_tn <- womens.cm$table["tested_positive","tested_positive"]
nn_fn <- womens.cm$table["tested_negative","tested_positive"]
nn_fp <- womens.cm$table["tested_positive","tested_negative"]
nn_fpr <- nn_fp/(nn_fp+nn_tn)
nn_tpr <- nn_tp/(nn_tp+nn_fn)
nn_accuracy <- womens.cm$overall['Accuracy']
# Wykres słupkowy
classificators <- matrix(c(knn1_accuracy, knn3_accuracy, knn5_accuracy, knn11_accuracy,
nb_accuracy, ctree_accuracy, nn_accuracy), ncol=7)
classificators.names <- matrix(c("1NN", "3NN", "5NN", "11NN", "NaiveBayes", "Trees", "NeuralNets"), ncol=7)
barplot(classificators, main="Skuteczność Klasyfikatorów", names.arg=classificators.names,
ylab="Skuteczność [%]", xlab="Klasyfikatory")
# Wykres punktowy
# FPR = FP/N = FP/(FP+TN) = 1 - SPC
# TPR = TP/P = TP/(TP+FN)
colors <- c("blue", "coral", "aquamarine", "cornflowerblue", "darkgreen", "burlywood3", "firebrick3")
fpr <- c(knn1_fpr, knn3_fpr, knn5_fpr, knn11_fpr, nb_fpr, ct_fpr, nn_fpr)
tpr <- c(knn1_tpr, knn3_tpr, knn5_tpr, knn11_fpr, nb_tpr, ct_tpr, nn_tpr)
plot(fpr, tpr, col=colors, bg=colors, pch=20, xlab="False Positive Rate", ylab="True Positive Rate",
main="False Positive and True Positive Ratings")
legend("bottomright", classificators.names, fill=colors)
plot(womens.nn)
str(titanic.raw)
str(Titanic)
df <- as.data.frame(Titanic)
head(df)
titanic.raw <- NULL
for(i in 1:4) {
titanic.raw <- cbind(titanic.raw, rep(as.character(df[,i]), df$Freq))
}
titanic.raw <- as.data.frame(titanic.raw)
names(titanic.raw) <- names(df)[1:4]
dim(titanic.raw)
summary(titanic.raw)
library(arules)
install.packages("arules")
library()
rules.all <- apriori(titanic.raw)
inspect(rules.all)
rules <- apriori(titanic.raw, control = list(verbose=F),
parameter = list(minlen=2, supp=0.005, conf=0.8),
appearance = list(rhs=c("Survived=No", "Survived=Yes"),
default="lhs"))
quality(rules) <- round(quality(rules), digits=3)
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
library(arulesViz)
plot(rules.all)
plot(rules.all, method="grouped")
plot(rules.all, method="graph")
net.bg <- barabasi.game(80)
plot(rules.all, method="paracoord", control=list(reorder=TRUE))
# Author: Zhuangfang Yi, find me on: http://geoyi.org.
setwd("you work file path/here you want your R codes to run")
list.files("you work file path")
titanic <- read.table('titanic_original.csv',header = TRUE, sep = ",")
summary(titanic)
library(dplyr)
library(mice)
library(VIM)
library(ggplot2)
#Checking the missing value from the data, e.g. which variable missing the most data, using library mice(a package in R)
md.pattern(titanic)
#making a missing value figure or plot using library VIM(a package in R)
NAPlot <- aggr(titanic, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
#above two lines of codes are just summary missing data and partten from the data.
#1: Port of embarkation
#somehow is.na and is.null in R can't detect empty value in titanic$embarked so I write this
is.na(titanic$embarked[titanic$embarked =='']) <- TRUE
sum(is.na(titanic$embarked))
#using replace function to replace NA by 'S' in titanic$embarked
titanic$embarked <- replace(titanic$embarked, which(is.na(titanic$embarked)), 'S')
#I would just run Sum function again to check if we replace all NAs seccessfully.
sum(is.na(titanic$embarked))
# 2: Age. from above plot we know that 20% of values are missing in Age.
Mage <- mean(titanic$age, na.rm = TRUE)
titanic$age <- replace(titanic$age, which(is.na(titanic$age)), Mage)
sum(is.na(titanic$age))
#3: Lifeboat
is.na(titanic$boat[titanic$boat =='']) <- TRUE
sum(is.na(titanic$boat))
#4: Cabin
CabinBi <- ifelse(titanic$cabin == '', 0, 1)
titanic <- titanic %>% mutate(has_cabin_number = CabinBi)
head(titanic, 4) #check first 4 row of new data titanic
#delete last row of my data
n<-dim(titanic)[1]
titanic <-titanic[1:(n-1),]
#recheck the data frame structure of the whole dataset.
str(titanic)
ggplot(titanic, aes(x = factor(pclass), fill = factor(sex))) +
geom_bar(position = "dodge")
ggplot(titanic, aes(x = factor(pclass), fill = factor(sex))) +
geom_bar(position = "dodge") +
facet_grid(. ~ survived)
posn.j <- position_jitter(0.5, 0)
ggplot(titanic, aes(x = factor(pclass), y = age, col = factor(sex))) +
geom_jitter(size = 3, alpha = 0.5, position = posn.j) +
facet_grid(. ~ survived)
# Author: Zhuangfang Yi, find me on: http://geoyi.org.
setwd("you work file path/here you want your R codes to run")
list.files("you work file path")
titanic <- read.table('/home/marcin/Your-survival-chance-in-Titanic-tragedy-using-R-/titanic_original.csv',header = TRUE, sep = ",")
summary(titanic)
library(dplyr)
library(mice)
library(VIM)
library(ggplot2)
#Checking the missing value from the data, e.g. which variable missing the most data, using library mice(a package in R)
md.pattern(titanic)
#making a missing value figure or plot using library VIM(a package in R)
NAPlot <- aggr(titanic, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
#above two lines of codes are just summary missing data and partten from the data.
#1: Port of embarkation
#somehow is.na and is.null in R can't detect empty value in titanic$embarked so I write this
is.na(titanic$embarked[titanic$embarked =='']) <- TRUE
sum(is.na(titanic$embarked))
#using replace function to replace NA by 'S' in titanic$embarked
titanic$embarked <- replace(titanic$embarked, which(is.na(titanic$embarked)), 'S')
#I would just run Sum function again to check if we replace all NAs seccessfully.
sum(is.na(titanic$embarked))
# 2: Age. from above plot we know that 20% of values are missing in Age.
Mage <- mean(titanic$age, na.rm = TRUE)
titanic$age <- replace(titanic$age, which(is.na(titanic$age)), Mage)
sum(is.na(titanic$age))
#3: Lifeboat
is.na(titanic$boat[titanic$boat =='']) <- TRUE
sum(is.na(titanic$boat))
#4: Cabin
CabinBi <- ifelse(titanic$cabin == '', 0, 1)
titanic <- titanic %>% mutate(has_cabin_number = CabinBi)
head(titanic, 4) #check first 4 row of new data titanic
#delete last row of my data
n<-dim(titanic)[1]
titanic <-titanic[1:(n-1),]
#recheck the data frame structure of the whole dataset.
str(titanic)
ggplot(titanic, aes(x = factor(pclass), fill = factor(sex))) +
geom_bar(position = "dodge")
ggplot(titanic, aes(x = factor(pclass), fill = factor(sex))) +
geom_bar(position = "dodge") +
facet_grid(. ~ survived)
posn.j <- position_jitter(0.5, 0)
ggplot(titanic, aes(x = factor(pclass), y = age, col = factor(sex))) +
geom_jitter(size = 3, alpha = 0.5, position = posn.j) +
facet_grid(. ~ survived)
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust",
"cluster", "igraph", "fpc")
install.packages(Needed, dependencies = TRUE)
install.packages("Rcampdf", repos = "http://datacube.wu.ac.at/", type = "source")
