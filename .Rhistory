knn3_tn <- cm_knn3$table["tested_positive","tested_positive"]
knn5_tn <- cm_knn5$table["tested_positive","tested_positive"]
knn11_tn <- cm_knn11$table["tested_positive","tested_positive"]
knn1_fn <- cm_knn1$table["tested_negative","tested_positive"]
knn3_fn <- cm_knn3$table["tested_negative","tested_positive"]
knn5_fn <- cm_knn5$table["tested_negative","tested_positive"]
knn11_fn <- cm_knn11$table["tested_negative","tested_positive"]
knn1_fp <- cm_knn1$table["tested_positive","tested_negative"]
knn3_fp <- cm_knn3$table["tested_positive","tested_negative"]
knn5_fp <- cm_knn5$table["tested_positive","tested_negative"]
knn11_fp <- cm_knn11$table["tested_positive","tested_negative"]
knn1_fpr <- knn1_fp/(knn1_fp+knn1_tn)
knn3_fpr <- knn3_fp/(knn3_fp+knn3_tn)
knn5_fpr <- knn5_fp/(knn5_fp+knn5_tn)
knn11_fpr <- knn11_fp/(knn11_fp+knn11_tn)
knn1_tpr <- knn1_tp/(knn1_tp+knn1_fn)
knn3_tpr <- knn3_tp/(knn3_tp+knn3_fn)
knn5_tpr <- knn5_tp/(knn5_tp+knn5_fn)
knn11_tpr <- knn11_tp/(knn11_tp+knn11_fn)
# NaiveBayes
nb <- naiveBayes(class ~ ., data=womens)
nb_pred <- predict(nb, womens[,-9])
cm_nb <- confusionMatrix(nb_pred, womens[,9])
nb_accuracy <- cm_nb$overall['Accuracy']
nb_tp <- cm_nb$table["tested_negative","tested_negative"]
nb_tn <- cm_nb$table["tested_positive","tested_positive"]
nb_fn <- cm_nb$table["tested_negative","tested_positive"]
nb_fp <- cm_nb$table["tested_positive","tested_negative"]
nb_fpr <- nb_fp/(nb_fp+nb_tn)
nb_tpr <- nb_tp/(nb_tp+nb_fn)
# Drzewa
womens_ctree <- ctree(class ~., data=womens)
ctree_pred <- predict(womens_ctree, womens[,-9])
cm_ctree <- confusionMatrix(ctree_pred, womens[,9])
ctree_accuracy <- cm_ctree$overall['Accuracy']
ct_tp <- cm_ctree$table["tested_negative","tested_negative"]
ct_tn <- cm_ctree$table["tested_positive","tested_positive"]
ct_fn <- cm_ctree$table["tested_negative","tested_positive"]
ct_fp <- cm_ctree$table["tested_positive","tested_negative"]
ct_fpr <- ct_fp/(ct_fp+ct_tn)
ct_tpr <- ct_tp/(ct_tp+ct_fn)
# Wykres słupkowy
classificators <- matrix(c(knn1_accuracy, knn3_accuracy, knn5_accuracy, knn11_accuracy,
nb_accuracy, ctree_accuracy), ncol=6)
classificators.names <- matrix(c("1NN", "3NN", "5NN", "11NN", "NaiveBayes", "Drzewa"), ncol=6)
barplot(classificators, main="Skuteczność Klasyfikatorów", names.arg=classificators.names,
ylab="Skuteczność [%]", xlab="Klasyfikatory")
# Wykres punktowy
# FPR = FP/N = FP/(FP+TN) = 1 - SPC
# TPR = TP/P = TP/(TP+FN)
colors <- c("blue", "coral", "aquamarine", "cornflowerblue", "darkgreen", "burlywood3")
fpr <- c(knn1_fpr, knn3_fpr, knn5_fpr, knn11_fpr, nb_fpr, ct_fpr)
tpr <- c(knn1_tpr, knn3_tpr, knn5_tpr, knn11_fpr, nb_tpr, ct_tpr)
plot(fpr, tpr, col=colors, bg=colors, pch=21, xlab="False Positive Rate", ylab="True Positive Rate",
main="False Positive and True Positive Ratings")
legend("bottomright", classificators.names, fill=colors)
library(class)
library(gmodels)
library(e1071)
library(party)
library(caret)
# Dane
womens = read.csv("/home/marcin/Computing-Inteligence-R/Lab3/diabetes.csv")
round(prop.table(table(womens$class)) * 100, digits = 1)
set.seed(1234)
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
cm_knn3 <- confusionMatrix(womens_pred3, womens.testLabels)
cm_knn5 <- confusionMatrix(womens_pred5, womens.testLabels)
cm_knn11 <- confusionMatrix(womens_pred11, womens.testLabels)
library(VIM)
library(deducorrect)
dirty.iris <- read.csv("/home/marcin/Computing-Inteligence-R/Lab4/dirty_iris.csv")
rules <- correctionRules("/home/marcin/Computing-Inteligence-R/Lab4/rules.txt")
correct.iris <- correctWithRules(rules, dirty.iris)
clean.iris.mean <- correct.iris$corrected
clean.iris.mean$Sepal.Length[is.na(clean.iris.mean$Sepal.Length)] <- mean(clean.iris.mean$Sepal.Length, na.rm = TRUE)
clean.iris.mean$Sepal.Width[is.na(clean.iris.mean$Sepal.Width)] <- mean(clean.iris.mean$Sepal.Width, na.rm = TRUE)
clean.iris.mean$Petal.Length[is.na(clean.iris.mean$Petal.Length)] <- mean(clean.iris.mean$Petal.Length, na.rm = TRUE)
clean.iris.mean$Petal.Width[is.na(clean.iris.mean$Petal.Width)] <- mean(clean.iris.mean$Petal.Width, na.rm = TRUE)
n <- nrow(clean.iris.mean)
for (i in 1:ncol(clean.iris.mean)) {
clean.iris.mean[sample(1:n, replace = TRUE), i] <- NA
}
clean.iris.knn <- kNN(clean.iris.mean)
# Dane
womens = read.csv("/home/marcin/Computing-Inteligence-R/Lab3/diabetes.csv")
round(prop.table(table(womens$class)) * 100, digits = 1)
set.seed(1234)
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
library(e1071)
library(class)
library(gmodels)
library(e1071)
library(party)
library(caret)
# Dane
womens = read.csv("/home/marcin/Computing-Inteligence-R/Lab3/diabetes.csv")
round(prop.table(table(womens$class)) * 100, digits = 1)
set.seed(1234)
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
cm_knn3 <- confusionMatrix(womens_pred3, womens.testLabels)
cm_knn5 <- confusionMatrix(womens_pred5, womens.testLabels)
cm_knn11 <- confusionMatrix(womens_pred11, womens.testLabels)
knn1_accuracy <- cm_knn1$overall['Accuracy']
knn3_accuracy <- cm_knn3$overall['Accuracy']
knn5_accuracy <- cm_knn5$overall['Accuracy']
knn11_accuracy <- cm_knn11$overall['Accuracy']
knn1_tp <- cm_knn1$table["tested_negative","tested_negative"]
knn3_tp <- cm_knn3$table["tested_negative","tested_negative"]
knn5_tp <- cm_knn5$table["tested_negative","tested_negative"]
knn11_tp <- cm_knn11$table["tested_negative","tested_negative"]
knn1_tn <- cm_knn1$table["tested_positive","tested_positive"]
knn3_tn <- cm_knn3$table["tested_positive","tested_positive"]
knn5_tn <- cm_knn5$table["tested_positive","tested_positive"]
knn11_tn <- cm_knn11$table["tested_positive","tested_positive"]
knn1_fn <- cm_knn1$table["tested_negative","tested_positive"]
knn3_fn <- cm_knn3$table["tested_negative","tested_positive"]
knn5_fn <- cm_knn5$table["tested_negative","tested_positive"]
knn11_fn <- cm_knn11$table["tested_negative","tested_positive"]
knn1_fp <- cm_knn1$table["tested_positive","tested_negative"]
knn3_fp <- cm_knn3$table["tested_positive","tested_negative"]
knn5_fp <- cm_knn5$table["tested_positive","tested_negative"]
knn11_fp <- cm_knn11$table["tested_positive","tested_negative"]
knn1_fpr <- knn1_fp/(knn1_fp+knn1_tn)
knn3_fpr <- knn3_fp/(knn3_fp+knn3_tn)
knn5_fpr <- knn5_fp/(knn5_fp+knn5_tn)
knn11_fpr <- knn11_fp/(knn11_fp+knn11_tn)
knn1_tpr <- knn1_tp/(knn1_tp+knn1_fn)
knn3_tpr <- knn3_tp/(knn3_tp+knn3_fn)
knn5_tpr <- knn5_tp/(knn5_tp+knn5_fn)
knn11_tpr <- knn11_tp/(knn11_tp+knn11_fn)
# NaiveBayes
nb <- naiveBayes(class ~ ., data=womens)
nb_pred <- predict(nb, womens[,-9])
cm_nb <- confusionMatrix(nb_pred, womens[,9])
nb_accuracy <- cm_nb$overall['Accuracy']
nb_tp <- cm_nb$table["tested_negative","tested_negative"]
nb_tn <- cm_nb$table["tested_positive","tested_positive"]
nb_fn <- cm_nb$table["tested_negative","tested_positive"]
nb_fp <- cm_nb$table["tested_positive","tested_negative"]
nb_fpr <- nb_fp/(nb_fp+nb_tn)
nb_tpr <- nb_tp/(nb_tp+nb_fn)
# Drzewa
womens_ctree <- ctree(class ~., data=womens)
ctree_pred <- predict(womens_ctree, womens[,-9])
cm_ctree <- confusionMatrix(ctree_pred, womens[,9])
ctree_accuracy <- cm_ctree$overall['Accuracy']
ct_tp <- cm_ctree$table["tested_negative","tested_negative"]
ct_tn <- cm_ctree$table["tested_positive","tested_positive"]
ct_fn <- cm_ctree$table["tested_negative","tested_positive"]
ct_fp <- cm_ctree$table["tested_positive","tested_negative"]
ct_fpr <- ct_fp/(ct_fp+ct_tn)
ct_tpr <- ct_tp/(ct_tp+ct_fn)
# Wykres słupkowy
classificators <- matrix(c(knn1_accuracy, knn3_accuracy, knn5_accuracy, knn11_accuracy,
nb_accuracy, ctree_accuracy), ncol=6)
classificators.names <- matrix(c("1NN", "3NN", "5NN", "11NN", "NaiveBayes", "Drzewa"), ncol=6)
barplot(classificators, main="Skuteczność Klasyfikatorów", names.arg=classificators.names,
ylab="Skuteczność [%]", xlab="Klasyfikatory")
# Wykres punktowy
# FPR = FP/N = FP/(FP+TN) = 1 - SPC
# TPR = TP/P = TP/(TP+FN)
colors <- c("blue", "coral", "aquamarine", "cornflowerblue", "darkgreen", "burlywood3")
fpr <- c(knn1_fpr, knn3_fpr, knn5_fpr, knn11_fpr, nb_fpr, ct_fpr)
tpr <- c(knn1_tpr, knn3_tpr, knn5_tpr, knn11_fpr, nb_tpr, ct_tpr)
plot(fpr, tpr, col=colors, bg=colors, pch=21, xlab="False Positive Rate", ylab="True Positive Rate",
main="False Positive and True Positive Ratings")
legend("bottomright", classificators.names, fill=colors)
#a
phi1 <- matrix(c(-1,-2,1,1,2,-1,1,2,3,-3,-2,-3,3,2,4,4,4,-4,-4,-4,3,0,0,0,0,0,0,0), ncol=4)
#b
phi2 <- as.matrix(read.csv("/home/marcin/Computing-Inteligence-R/Lab1/dubois20.cnf.txt", header=FALSE, skip=13, sep="", colClasses=c(NA,NA,NA,"NULL")))
#c
fitness = function(temp, phi){
licz = 0
wynik = FALSE
max = max(as.numeric(unlist(phi)))
for(i in 1:nrow(phi)){
row <- phi[i,]
row_1 <- abs(row[1])%%3
if(row_1 == 0){ row_1 = 3}
row_2 <- abs(row[2])%%3
if(row_2 == 0){ row_2 = 3}
row_3 <- abs(row[3])%%3
if(row_3 == 0){ row_3 = 3}
x1 = temp[row_1]
if(row[1] < 0){ x1 = !x1 }
x2 = temp[row_2]
if(row[2] < 0){ x2 = !x2 }
x3 = temp[row_3]
if(row[3] < 0){ x3 = !x3 }
wynik = x1 | x2 | x3
if(!is.na(wynik)){ if(wynik){ licz = licz + 1 } }
}
return(licz)
}
#d
licz = fitness(c(1,0,1,1), phi1)
library(VIM)
library(deducorrect)
dirty.iris <- read.csv("/home/marcin/Computing-Inteligence-R/Lab4/dirty_iris.csv")
rules <- correctionRules("/home/marcin/Computing-Inteligence-R/Lab4/rules.txt")
correct.iris <- correctWithRules(rules, dirty.iris)
clean.iris.mean <- correct.iris$corrected
clean.iris.mean$Sepal.Length[is.na(clean.iris.mean$Sepal.Length)] <- mean(clean.iris.mean$Sepal.Length, na.rm = TRUE)
clean.iris.mean$Sepal.Width[is.na(clean.iris.mean$Sepal.Width)] <- mean(clean.iris.mean$Sepal.Width, na.rm = TRUE)
clean.iris.mean$Petal.Length[is.na(clean.iris.mean$Petal.Length)] <- mean(clean.iris.mean$Petal.Length, na.rm = TRUE)
clean.iris.mean$Petal.Width[is.na(clean.iris.mean$Petal.Width)] <- mean(clean.iris.mean$Petal.Width, na.rm = TRUE)
n <- nrow(clean.iris.mean)
for (i in 1:ncol(clean.iris.mean)) {
clean.iris.mean[sample(1:n, replace = TRUE), i] <- NA
}
clean.iris.knn <- kNN(clean.iris.mean)
View(clean.iris.knn)
library(deducorrect)
dirty.iris <- read.csv("/home/marcin/Computing-Inteligence-R/Lab4/dirty_iris.csv")
rules <- correctionRules("/home/marcin/Computing-Inteligence-R/Lab4/rules.txt")
correct.iris <- correctWithRules(rules, dirty.iris)
clean.iris.mean <- correct.iris$corrected
clean.iris.mean$Sepal.Length[is.na(clean.iris.mean$Sepal.Length)] <- mean(clean.iris.mean$Sepal.Length, na.rm = TRUE)
clean.iris.mean$Sepal.Width[is.na(clean.iris.mean$Sepal.Width)] <- mean(clean.iris.mean$Sepal.Width, na.rm = TRUE)
clean.iris.mean$Petal.Length[is.na(clean.iris.mean$Petal.Length)] <- mean(clean.iris.mean$Petal.Length, na.rm = TRUE)
clean.iris.mean$Petal.Width[is.na(clean.iris.mean$Petal.Width)] <- mean(clean.iris.mean$Petal.Width, na.rm = TRUE)
n <- nrow(clean.iris.mean)
for (i in 1:ncol(clean.iris.mean)) {
clean.iris.mean[sample(1:n, replace = TRUE), i] <- NA
}
clean.iris.knn <- kNN(clean.iris.mean)
library(VIM)
library(deducorrect)
dirty.iris <- read.csv("/home/marcin/Computing-Inteligence-R/Lab4/dirty_iris.csv")
rules <- correctionRules("/home/marcin/Computing-Inteligence-R/Lab4/rules.txt")
correct.iris <- correctWithRules(rules, dirty.iris)
clean.iris.mean <- correct.iris$corrected
clean.iris.mean$Sepal.Length[is.na(clean.iris.mean$Sepal.Length)] <- mean(clean.iris.mean$Sepal.Length, na.rm = TRUE)
clean.iris.mean$Sepal.Width[is.na(clean.iris.mean$Sepal.Width)] <- mean(clean.iris.mean$Sepal.Width, na.rm = TRUE)
clean.iris.mean$Petal.Length[is.na(clean.iris.mean$Petal.Length)] <- mean(clean.iris.mean$Petal.Length, na.rm = TRUE)
clean.iris.mean$Petal.Width[is.na(clean.iris.mean$Petal.Width)] <- mean(clean.iris.mean$Petal.Width, na.rm = TRUE)
n <- nrow(clean.iris.mean)
for (i in 1:ncol(clean.iris.mean)) {
clean.iris.mean[sample(1:n, replace = TRUE), i] <- NA
}
clean.iris.knn <- kNN(clean.iris.mean)
library(VIM)
library(deducorrect)
dirty.iris <- read.csv("/home/marcin/Computing-Inteligence-R/Lab4/dirty_iris.csv")
rules <- correctionRules("/home/marcin/Computing-Inteligence-R/Lab4/rules.txt")
correct.iris <- correctWithRules(rules, dirty.iris)
clean.iris.mean <- correct.iris$corrected
clean.iris.mean$Sepal.Length[is.na(clean.iris.mean$Sepal.Length)] <- mean(clean.iris.mean$Sepal.Length, na.rm = TRUE)
clean.iris.mean$Sepal.Width[is.na(clean.iris.mean$Sepal.Width)] <- mean(clean.iris.mean$Sepal.Width, na.rm = TRUE)
clean.iris.mean$Petal.Length[is.na(clean.iris.mean$Petal.Length)] <- mean(clean.iris.mean$Petal.Length, na.rm = TRUE)
clean.iris.mean$Petal.Width[is.na(clean.iris.mean$Petal.Width)] <- mean(clean.iris.mean$Petal.Width, na.rm = TRUE)
n <- nrow(clean.iris.mean)
for (i in 1:ncol(clean.iris.mean)) {
clean.iris.mean[sample(1:n, replace = TRUE), i] <- NA
}
clean.iris.knn <- kNN(clean.iris.mean)
View(clean.iris.knn)
library(class)
library(gmodels)
library(e1071)
library(party)
library(caret)
# Dane
womens = read.csv("/home/marcin/Computing-Inteligence-R/Lab3/diabetes.csv")
round(prop.table(table(womens$class)) * 100, digits = 1)
set.seed(1234)
ind <- sample(2, nrow(womens), replace=TRUE, prob=c(0.67, 0.33))
womens.training <- womens[ind==1, 1:8]
womens.test <- womens[ind==2, 1:8]
womens.trainLabels <- womens[ind==1, 9]
womens.testLabels <- womens[ind==2, 9]
# kNN
cm_knn1 <- confusionMatrix(womens_pred1, womens.testLabels)
cm_knn3 <- confusionMatrix(womens_pred3, womens.testLabels)
cm_knn5 <- confusionMatrix(womens_pred5, womens.testLabels)
cm_knn11 <- confusionMatrix(womens_pred11, womens.testLabels)
knn1_accuracy <- cm_knn1$overall['Accuracy']
knn3_accuracy <- cm_knn3$overall['Accuracy']
knn5_accuracy <- cm_knn5$overall['Accuracy']
knn11_accuracy <- cm_knn11$overall['Accuracy']
knn1_tp <- cm_knn1$table["tested_negative","tested_negative"]
knn3_tp <- cm_knn3$table["tested_negative","tested_negative"]
knn5_tp <- cm_knn5$table["tested_negative","tested_negative"]
knn11_tp <- cm_knn11$table["tested_negative","tested_negative"]
knn1_tn <- cm_knn1$table["tested_positive","tested_positive"]
knn3_tn <- cm_knn3$table["tested_positive","tested_positive"]
knn5_tn <- cm_knn5$table["tested_positive","tested_positive"]
knn11_tn <- cm_knn11$table["tested_positive","tested_positive"]
knn1_fn <- cm_knn1$table["tested_negative","tested_positive"]
knn3_fn <- cm_knn3$table["tested_negative","tested_positive"]
knn5_fn <- cm_knn5$table["tested_negative","tested_positive"]
knn11_fn <- cm_knn11$table["tested_negative","tested_positive"]
knn1_fp <- cm_knn1$table["tested_positive","tested_negative"]
knn3_fp <- cm_knn3$table["tested_positive","tested_negative"]
knn5_fp <- cm_knn5$table["tested_positive","tested_negative"]
knn11_fp <- cm_knn11$table["tested_positive","tested_negative"]
knn1_fpr <- knn1_fp/(knn1_fp+knn1_tn)
knn3_fpr <- knn3_fp/(knn3_fp+knn3_tn)
knn5_fpr <- knn5_fp/(knn5_fp+knn5_tn)
knn11_fpr <- knn11_fp/(knn11_fp+knn11_tn)
knn1_tpr <- knn1_tp/(knn1_tp+knn1_fn)
knn3_tpr <- knn3_tp/(knn3_tp+knn3_fn)
knn5_tpr <- knn5_tp/(knn5_tp+knn5_fn)
knn11_tpr <- knn11_tp/(knn11_tp+knn11_fn)
# NaiveBayes
nb <- naiveBayes(class ~ ., data=womens)
nb_pred <- predict(nb, womens[,-9])
cm_nb <- confusionMatrix(nb_pred, womens[,9])
nb_accuracy <- cm_nb$overall['Accuracy']
nb_tp <- cm_nb$table["tested_negative","tested_negative"]
nb_tn <- cm_nb$table["tested_positive","tested_positive"]
nb_fn <- cm_nb$table["tested_negative","tested_positive"]
nb_fp <- cm_nb$table["tested_positive","tested_negative"]
nb_fpr <- nb_fp/(nb_fp+nb_tn)
nb_tpr <- nb_tp/(nb_tp+nb_fn)
# Drzewa
womens_ctree <- ctree(class ~., data=womens)
ctree_pred <- predict(womens_ctree, womens[,-9])
cm_ctree <- confusionMatrix(ctree_pred, womens[,9])
ctree_accuracy <- cm_ctree$overall['Accuracy']
ct_tp <- cm_ctree$table["tested_negative","tested_negative"]
ct_tn <- cm_ctree$table["tested_positive","tested_positive"]
ct_fn <- cm_ctree$table["tested_negative","tested_positive"]
ct_fp <- cm_ctree$table["tested_positive","tested_negative"]
ct_fpr <- ct_fp/(ct_fp+ct_tn)
ct_tpr <- ct_tp/(ct_tp+ct_fn)
# Wykres słupkowy
classificators <- matrix(c(knn1_accuracy, knn3_accuracy, knn5_accuracy, knn11_accuracy,
nb_accuracy, ctree_accuracy), ncol=6)
classificators.names <- matrix(c("1NN", "3NN", "5NN", "11NN", "NaiveBayes", "Drzewa"), ncol=6)
barplot(classificators, main="Skuteczność Klasyfikatorów", names.arg=classificators.names,
ylab="Skuteczność [%]", xlab="Klasyfikatory")
# Wykres punktowy
# FPR = FP/N = FP/(FP+TN) = 1 - SPC
# TPR = TP/P = TP/(TP+FN)
colors <- c("blue", "coral", "aquamarine", "cornflowerblue", "darkgreen", "burlywood3")
fpr <- c(knn1_fpr, knn3_fpr, knn5_fpr, knn11_fpr, nb_fpr, ct_fpr)
tpr <- c(knn1_tpr, knn3_tpr, knn5_tpr, knn11_fpr, nb_tpr, ct_tpr)
plot(fpr, tpr, col=colors, bg=colors, pch=21, xlab="False Positive Rate", ylab="True Positive Rate",
main="False Positive and True Positive Ratings")
legend("bottomright", classificators.names, fill=colors)
#a
phi1 <- matrix(c(-1,-2,1,1,2,-1,1,2,3,-3,-2,-3,3,2,4,4,4,-4,-4,-4,3,0,0,0,0,0,0,0), ncol=4)
#b
phi2 <- as.matrix(read.csv("/home/marcin/Computing-Inteligence-R/Lab1/dubois20.cnf.txt", header=FALSE, skip=13, sep="", colClasses=c(NA,NA,NA,"NULL")))
#c
fitness = function(temp, phi){
licz = 0
wynik = FALSE
max = max(as.numeric(unlist(phi)))
for(i in 1:nrow(phi)){
row <- phi[i,]
row_1 <- abs(row[1])%%3
if(row_1 == 0){ row_1 = 3}
row_2 <- abs(row[2])%%3
if(row_2 == 0){ row_2 = 3}
row_3 <- abs(row[3])%%3
if(row_3 == 0){ row_3 = 3}
x1 = temp[row_1]
if(row[1] < 0){ x1 = !x1 }
x2 = temp[row_2]
if(row[2] < 0){ x2 = !x2 }
x3 = temp[row_3]
if(row[3] < 0){ x3 = !x3 }
wynik = x1 | x2 | x3
if(!is.na(wynik)){ if(wynik){ licz = licz + 1 } }
}
return(licz)
}
#d
licz = fitness(c(1,0,1,1), phi1)
#a
phi1 <- matrix(c(-1,-2,1,1,2,-1,1,2,3,-3,-2,-3,3,2,4,4,4,-4,-4,-4,3,0,0,0,0,0,0,0), ncol=4)
#b
phi2 <- as.matrix(read.csv("/home/marcin/Computing-Inteligence-R/Lab1/dubois20.cnf.txt", header=FALSE, skip=13, sep="", colClasses=c(NA,NA,NA,"NULL")))
#c
fitness = function(temp, phi){
licz = 0
wynik = FALSE
max = max(as.numeric(unlist(phi)))
for(i in 1:nrow(phi)){
row <- phi[i,]
row_1 <- abs(row[1])%%3
if(row_1 == 0){ row_1 = 3}
row_2 <- abs(row[2])%%3
if(row_2 == 0){ row_2 = 3}
row_3 <- abs(row[3])%%3
if(row_3 == 0){ row_3 = 3}
x1 = temp[row_1]
if(row[1] < 0){ x1 = !x1 }
x2 = temp[row_2]
if(row[2] < 0){ x2 = !x2 }
x3 = temp[row_3]
if(row[3] < 0){ x3 = !x3 }
wynik = x1 | x2 | x3
if(!is.na(wynik)){ if(wynik){ licz = licz + 1 } }
}
return(licz)
}
#d
licz = fitness(c(1,0,1,1), phi1)
#d
licz = fitness(c(1,1,1,0), phi1)
#a
phi1 <- matrix(c(-1,-2,1,1,2,-1,1,2,3,-3,-2,-3,3,2,4,4,4,-4,-4,-4,3,0,0,0,0,0,0,0), ncol=4)
#b
phi2 <- as.matrix(read.csv("/home/marcin/Computing-Inteligence-R/Lab1/dubois20.cnf.txt", header=FALSE, skip=13, sep="", colClasses=c(NA,NA,NA,"NULL")))
#c
fitness = function(temp, phi){
licz = 0
wynik = FALSE
max = max(as.numeric(unlist(phi)))
for(i in 1:nrow(phi)){
row <- phi[i,]
row_1 <- abs(row[1])%%3
if(row_1 == 0){ row_1 = 3}
row_2 <- abs(row[2])%%3
if(row_2 == 0){ row_2 = 3}
row_3 <- abs(row[3])%%3
if(row_3 == 0){ row_3 = 3}
x1 = temp[row_1]
if(row[1] < 0){ x1 = !x1 }
x2 = temp[row_2]
if(row[2] < 0){ x2 = !x2 }
x3 = temp[row_3]
if(row[3] < 0){ x3 = !x3 }
wynik = x1 | x2 | x3
if(!is.na(wynik)){ if(wynik){ licz = licz + 1 } }
}
return(licz)
}
#d
licz = fitness(c(1,1,1,0), phi1)
iris.numeric <- as.matrix(iris[,-5], col.names=F)
View(iris.numeric)
log(iris.numeric)
View(iris.numeric)
iris <- prcomp(iris)
iris <- prcomp(iris, is.na(TRUE))
iris.numeric <- as.matrix(iris[,-5], col.names=F)
iris.log <- log(iris.numeric)
iris.preproc <- scale(iris.log)
iris.pca <- prcomp(iris.preproc)
iris.numeric <- as.matrix(iris[,-5], col.names=F)
iris.log <- log(iris.numeric)
iris.preproc <- scale(iris.log)
iris.pca <- prcomp(iris.preproc)
View(iris.pca)
View(iris.pca)
plot(iris.pca)
iris.pca.data <- iris.pca.data[,-3]
iris.pca <- prcomp(iris.preproc)
iris.pca.data <- predict(iris.pca)
View(iris.pca.data)
iris.pca.data <- iris.pca.data[,1,2]
iris.pca.data <- iris.pca.data[1,2]
View(iris.pca)
iris.pca.data <- iris.pca.data[,-2]
iris.pca.data <- predict(iris.pca)
iris.pca.data <- iris.pca.data[,-2]
iris.pca.data <- predict(iris.pca)[1:2]
View(iris.pca)
plot(iris.pca.data)
iris.pca.data <- predict(iris.pca)[,1:2]
plot(iris.pca.data)
plot(iris)
iris <- kmeans(iris.pca.data)
plot(iris)
iris.pca <- prcomp(iris.preproc)
iris.pca.data <- predict(iris.pca)[,1:2]
iris <- kmeans(iris.pca.data)
plot(iris)
iris.numeric <- as.matrix(iris[,-5], col.names=F)
iris.log <- log(iris.numeric)
iris.preproc <- scale(iris.log)
iris.pca <- prcomp(iris.preproc)
iris.pca.data <- predict(iris.pca)[,1:2]
iris.m <- kmeans(iris.pca.data)
plot(iris.m)
iris.numeric <- as.matrix(iris[,-5], col.names=F)
iris.log <- log(iris.numeric)
iris.preproc <- scale(iris.log)
iris.pca <- prcomp(iris.preproc)
iris.pca.data <- predict(iris.pca)[,1:2]
iris.m <- kmeans(iris.pca.data)
plot(iris.m)
